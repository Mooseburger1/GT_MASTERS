{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "## Implementing EM for MNIST dataset, with PCA for dimensionality reduction.\n",
    "\n",
    "Implement the EM algorithm for fitting a Gaussian mixture model for the MNIST dataset.\n",
    "We reduce the dataset to be only two cases, of digits “2” and “6” only. Thus, you will fit\n",
    "GMM with C = 2. Use the data file data.mat or data.dat. True label of the data are also\n",
    "provided in label.mat and label.dat\n",
    "The matrix images is of size 784-by-1990, i.e., there are totally 1990 images, and each\n",
    "column of the matrix corresponds to one image of size 28-by-28 pixels (the image is vectorized;\n",
    "the original image can be recovered by map the vector into a matrix).\n",
    "First use PCA to reduce the dimensionality of the data before applying to EM. We will\n",
    "put all “6” and “2” digits together, to project the original data into 5-dimensional vectors.\n",
    "Now implement EM algorithm for the projected data (with 5-dimensions).\n",
    "\n",
    "#### 1. Select from data one raw image of “2” and “6” and visualize them, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('data.mat')['data'].T\n",
    "labels = loadmat('label.mat')['trueLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "two = data[0, :]\n",
    "six = data[-1, :]\n",
    "\n",
    "orig_shape = (28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(nrows=1, ncols=2, figsize=(15,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(two.reshape(orig_shape).T, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(six.reshape(orig_shape).T, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write down detailed expression of the E-step and M-step in the EM algorithm (hint: when computing τ k i , you can drop the (2π) n/2 factor from the numerator and denominator expression, since it will be canceled out; this can help avoid some numerical issues in computation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Implement EM algorithm yourself. Use the following initialization\n",
    "* initialization for mean: random Gaussian vector with zero mean\n",
    "* initialization for covariance: generate two Gaussian random matrix of size n-by- n: $S_1$ and $S_2$ , and initialize the covariance matrix for the two components are $\\Sigma_1 = S_1S_1^T + I_n$ , and $\\Sigma_2 = S_2S_2^T + I_n$ , where $I_n$ is an identity matrix of size n-by-n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, K: int, maxIter: int, tol=1e-3) -> None:\n",
    "        \n",
    "        #Number of gaussian clusters\n",
    "        self.K = K\n",
    "        self.maxIter = maxIter\n",
    "        self.tol = tol\n",
    "        \n",
    "    def fit(self, X: np.array):\n",
    "        \n",
    "        assert len(X.shape) >= 2, 'If passing a vector of data, ensure two dimensions by reshaping data \"X.reshape(-1,1)\"'\n",
    "        #initialize clusters\n",
    "        self._initialize(X=X)\n",
    "        \n",
    "        for i in range(self.maxIter):\n",
    "            \n",
    "            print('.........iteration {}.........'.format(i))\n",
    "            #run the E step\n",
    "            self._expectation(X)\n",
    "            \n",
    "            #run the M step\n",
    "            self._maximization(X)\n",
    "            \n",
    "            diff = np.linalg.norm(self.mus - self.mus_old)\n",
    "\n",
    "            if np.linalg.norm(self.mus-self.mus_old) < self.tol:\n",
    "                print('Converged!')\n",
    "                break\n",
    "            \n",
    "            self.mus_old = self.mus.copy()\n",
    "        \n",
    "        if i == self.maxIter-1:\n",
    "            print('Max iterations reached')\n",
    "    \n",
    "    def _initialize(self, X):\n",
    "        #get shape of the data\n",
    "        m,n = X.shape\n",
    "        \n",
    "        #initialize K-gaussian clusters with mean randomly sampled from 0 centered Gaussian\n",
    "        self.mus = np.random.randn(self.K, n)\n",
    "        self.mus_old = self.mus.copy()\n",
    "        \n",
    "        #initialize K-covariance matrices\n",
    "        self.covs = []\n",
    "        for _ in range(self.K):\n",
    "            S = np.random.randn(n,n)\n",
    "            S = S@S.T + np.eye(n)\n",
    "            self.covs.append(S)\n",
    "\n",
    "        \n",
    "        #initialize priors\n",
    "        self.pis = np.random.random(self.K)\n",
    "        self.pis = self.pis / np.sum(self.pis)\n",
    "        \n",
    "        #initialize the posterior\n",
    "        self.tau = np.full((m,self.K), fill_value=0.)\n",
    "        \n",
    "    def _expectation(self, X: np.array):\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            self.tau[:, i] = self.pis[i] * multivariate_normal.pdf(X, \n",
    "                                                                   self.mus[i], \n",
    "                                                                   self.covs[i])\n",
    "        #normalize tau\n",
    "        sum_tau = np.sum(self.tau, axis=1).reshape(-1,1)\n",
    "        self.tau = np.divide(self.tau, np.tile(sum_tau, (1,self.K)))\n",
    "        \n",
    "    def _maximization(self, X: np.array):\n",
    "        \n",
    "        m,n = X.shape\n",
    "        \n",
    "        for i in range(self.K):\n",
    "            \n",
    "            #update priors\n",
    "            self.pis[i] = np.sum(self.tau[:,i]) / m\n",
    "            \n",
    "            #update cluster mean\n",
    "            self.mus[i] = X.T @ self.tau[:, i] / np.sum(self.tau[:,i], axis=0)\n",
    "            \n",
    "            #update cluster covariance\n",
    "            dummy = X - np.tile(self.mus[i], (m,1))\n",
    "            self.covs[i] = dummy.T @ np.diag(self.tau[:, i]) @ dummy / np.sum(self.tau[:,i], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = GMM(3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fit(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1990, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda496e4f14cb09440c9a1e4075475d115c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
