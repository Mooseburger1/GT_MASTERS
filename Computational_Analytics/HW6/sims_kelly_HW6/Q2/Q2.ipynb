{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 {-}\n",
    "## Linear regression: bias-variance tradeoff, CV, and variable selection {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider a dataset with n data points $(x^i , y^i ), x^i ∈ \\mathbb{R}^n$ , following from the following linear model:\n",
    "\n",
    "$$\n",
    "y^i = \\beta^{*^T} x^i + \\epsilon^i, \\ \\ \\ \\ \\ \\ \\text{i = 1, ...,m,}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\epsilon^i$ are i.i.d. Gaussian noise with zero mean and variance $σ^2$ , and $β^∗$ is the true parameter.\n",
    "Consider the ridge regression as follows:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}(\\lambda) = \\text{argmin}_{\\beta}{\\frac{1}{m} \\sum_{i=1}^{m}(y^i - \\beta^T x^i)^2 + \\lambda ||\\beta||_2^2}\n",
    "$$\n",
    "\n",
    "where $\\lambda \\leq 0$ is the regularized parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Find the closed form solution for $\\hat{\\beta}(\\lambda)$ and its distribution conditioning on ${x^i}$ (i.e., treat them as fixed). {-}\n",
    "\n",
    "##### **Answer** {-}\n",
    "Rewriting the equation into matrix form produces:\n",
    "\n",
    "$$\n",
    "|| y-X \\beta||_2^2 + \\lambda || \\beta ||_2^2\\ \\ \\ \\ (1)\n",
    "$$\n",
    "\n",
    "Taking the derivative of (1) with respect $\\beta$ and setting equal to 0 yields\n",
    "\n",
    "$$\n",
    "= (2y-2X\\beta)X + (2\\lambda\\beta) = 0\n",
    "\\\\\n",
    "= (2X^Ty - 2X^TX\\beta) + (2\\lambda\\beta) = 0\n",
    "\\\\\n",
    "= (X^Ty - X^TX\\beta) + (\\lambda\\beta) = 0\\ \\ \\ \\ (2)\n",
    "$$\n",
    "\n",
    "Solving (2) for $\\beta$ yields\n",
    "\n",
    "$$\n",
    "X^Ty = X^TX\\beta + \\lambda\\beta\n",
    "\\\\\n",
    "X^Ty = (X^TX + \\lambda I)\\beta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boxed{(X^TX + \\lambda I)^{-1}X^Ty = \\beta}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Calculate the bias $E[x^T β̂(λ)] − x^T β^∗$ as a function of λ and some fixed test point x.\n",
    "\n",
    "##### **Answer**\n",
    "\n",
    "Since y in the answer above is \n",
    "\n",
    "$$\n",
    "y = (X\\beta + \\epsilon)\n",
    "$$\n",
    "\n",
    "We can rewrite it as \n",
    "\n",
    "$$\n",
    "\\beta = (X^TX + \\lambda I)^{-1} X^T(X\\beta + \\epsilon)\n",
    "$$\n",
    "\n",
    "Expanding produces:\n",
    "$$\n",
    "(X^TX + \\lambda I)^{-1} X^TX\\beta + (X^TX + \\lambda I)^{-1} X^T \\epsilon\n",
    "$$\n",
    "\n",
    "Since we desire $E[\\beta]$ the equation above becomes\n",
    "\n",
    "$$\n",
    "(X^TX + \\lambda I)^{-1} X^TX\\beta + (X^TX + \\lambda I)^{-1} X^T E[\\epsilon]\n",
    "$$\n",
    "\n",
    "Since $\\epsilon$ is i.i.d with mean 0 and variance $\\sigma^2$, then $E[\\epsilon] = 0$ which reduces the above to\n",
    "\n",
    "$$\n",
    "(X^TX + \\lambda I)^{-1} X^TX\\beta\n",
    "$$\n",
    "\n",
    "Therefore\n",
    "$$\n",
    "E[x^T\\beta(\\lambda)] - x^T\\beta^* \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boxed{(X^TX + \\lambda I)^{-1} X^TX\\beta - x^T\\beta^*}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Calculate the variance term $E[(x^T \\hat{\\beta}(\\lambda) - E[x^T \\hat{\\beta}(\\lambda)])^2]$ as a function of λ {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting from above that\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}(\\lambda) = (X^TX + \\lambda I)^{-1} X^TX\\beta\n",
    "$$\n",
    "\n",
    "since var is under the convention of $[C^TC]$ we have\n",
    "\n",
    "$$\n",
    "(X^TX + \\lambda I)^{-1} X^TX\\beta [(X^TX + \\lambda I)^{-1} X^TX\\beta]^T \\\\ \n",
    "= (X^TX + \\lambda I)^{-1} X^TX [\\beta^T\\beta](X^TX + \\lambda I)^{-1} X^TX\\beta\n",
    "$$\n",
    "\n",
    "Keeping note that $[\\beta^T\\beta] = \\sigma^2(X^TX)^{-1}$ the above equation reduces down to\n",
    "\n",
    "$$\n",
    "\\boxed{\\sigma^2 (X^TX + \\lambda I)^{-1}X^TX(X^TX + \\lambda I)^{-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the results from parts (b) and (c) and the bias-variance decomposition to analyze the impact of λ in the mean squared error. Specifically, which term dominates when λ is small, and large, respectively? {-}\n",
    "\n",
    "Since $MSE = bias^2 + var$, it is easy to see from the above two equations for bias and variance, when $\\lambda$ is large, the variance term dominates. conversely when $\\lambda$ is small, the bias term dominates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now suppose we have m = 100 samples. Write a pseudo-code to explain how to use cross validation to find the optimal λ. {-}\n",
    "\n",
    "* Initialize range of hyperparameter $\\lambda$\n",
    "* Divide data of size m by number of folds k\n",
    "* for each fold DO:\n",
    "    * fold is holdout set\n",
    "    * For each hyperparameter $\\lambda$ DO:\n",
    "        * Train model on k-1 folds\n",
    "        * Eval model on holdout fold\n",
    "        * If best evaluation, keep params\n",
    "    * end \n",
    "* end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain if we would like to perform variable selection, how should we change the regularization term in Equation (1) to achieve this goal. {-}\n",
    "\n",
    "If we want to achieve a model which in essence performs variable selection, we wish to regularize the objective function such that it drives coefficient sparsity. Therefore, we can change ridge regression to LASSO regression to do this by optimizing the absolute value of the regularization term (L1 regularization)\n",
    "\n",
    "$$\n",
    "|| y-X \\beta||_2^2 + \\lambda || \\beta ||_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
