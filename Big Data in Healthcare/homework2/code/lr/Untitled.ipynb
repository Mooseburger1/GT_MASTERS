{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lrsgd as lr\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.88079708])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.sigmoid(z=np.array([0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not use anything outside of the standard distribution of python\n",
    "# when implementing this class\n",
    "\n",
    "#NOTES: eta is learning rate\n",
    "#NOTES: mu is regularization constant\n",
    "#NOTES: n_feature is total features present from etl\n",
    "import math \n",
    "\n",
    "class LogisticRegressionSGD:\n",
    "    \"\"\"\n",
    "    Logistic regression with stochastic gradient descent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eta, mu, n_feature):\n",
    "        \"\"\"\n",
    "        Initialization of model parameters\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "        self.weight = [0.0] * n_feature\n",
    "        self.b = 0\n",
    "        self.count = 0\n",
    "        self.costs = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Update model using a pair of training sample\n",
    "        \"\"\"\n",
    "        cost = self.optimize(X,y)\n",
    "        \n",
    "        \n",
    "        self.costs.append(cost)\n",
    "        self.count+=1\n",
    "        \n",
    "        if self.count % 100 == 0:\n",
    "            print('Cost at Observation {}: {}'.format(self.count, cost))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict 0 or 1 given X and the current weights in the model\n",
    "        \"\"\"\n",
    "        \n",
    "        return 1 if self.predict_prob(X) > 0.5 else 0\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        \"\"\"\n",
    "        Sigmoid function\n",
    "        \"\"\"\n",
    "        return 1.0 / (1.0 + math.exp(-math.fsum((self.weight[f]*v for f, v in X))))\n",
    "    \n",
    "    def propagate(self, w, b, X, Y):\n",
    "        #X is in the form [(position, value), (position, value), ...]\n",
    "        #forwardprop\n",
    "        z = math.fsum([x[1]*w[x[0]] for x in X]) + b\n",
    "        A = 1 / (1 + math.exp(-z))\n",
    "        cost = -(Y*math.log(A) + (1-Y)*math.log(1-A))\n",
    "        \n",
    "        #backprop\n",
    "        dz = A - Y\n",
    "        dw = [(x[0],x[1]*dz) for x in X]\n",
    "        db = dz\n",
    "        \n",
    "        grads = {\"dw\":dw, \"db\":db}\n",
    "        \n",
    "        return grads, cost\n",
    "    \n",
    "    def optimize(self,X, Y):\n",
    "        \n",
    "        grads, cost = self.propagate(self.weight, self.b, X, Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        \n",
    "        for idx, value in dw:\n",
    "            self.weight[idx] = self.weight[idx] - (self.eta * value)\n",
    "            \n",
    "        self.b = self.b - (self.eta*db)\n",
    "        \n",
    "        \n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = [(10, 1.0), (12, 1.0), (14, 1.0), (15, 1.0), (17, 1.0), (18, 1.0), (20, 1.0), (21, 1.0), (29, 1.0), (37, 1.0), (50, 1.0), (51, 0.5), (54, 1.0), (55, 1.0), (57, 1.0), (58, 1.0), (60, 1.0), (65, 1.0), (66, 1.0), (68, 0.75), (72, 1.0), (73, 1.0), (76, 0.666667), (78, 1.0), (79, 1.0), (80, 1.0), (82, 1.0), (83, 1.0), (84, 0.428571), (85, 0.5), (86, 1.0), (87, 1.0), (89, 0.125), (90, 1.0), (91, 1.0), (92, 1.0), (94, 1.0), (97, 1.0), (101, 1.0), (104, 1.0), (105, 1.0), (106, 1.0), (107, 1.0), (108, 0.5), (109, 1.0), (112, 1.0), (113, 0.333333), (114, 1.0), (115, 1.0), (116, 0.25), (117, 1.0), (118, 1.0), (119, 0.333333), (121, 1.0), (122, 1.0), (123, 1.0), (125, 1.0), (126, 1.0), (127, 1.0), (129, 0.5), (130, 1.0), (133, 0.4), (134, 1.0), (135, 1.0), (136, 0.25), (138, 0.5), (139, 1.0), (141, 1.0), (143, 1.0), (144, 1.0), (146, 1.0), (147, 1.0), (148, 1.0), (149, 1.0), (151, 0.5), (152, 1.0), (153, 1.0), (154, 1.0), (157, 1.0), (158, 0.25), (159, 0.333333), (161, 1.0), (163, 0.666667), (164, 1.0), (165, 0.5), (168, 0.285714), (169, 1.0), (170, 0.285714), (171, 1.0), (173, 1.0), (175, 0.5), (177, 1.0), (178, 0.25), (179, 0.5), (180, 1.0), (181, 1.0), (184, 1.0), (188, 1.0), (189, 1.0), (191, 0.75), (193, 1.0), (195, 1.0), (197, 1.0), (198, 0.666667), (199, 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionSGD(0.01, 0.5, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at Observation 20100: 0.03679843122765987\n",
      "Cost at Observation 20200: 0.027114131358538407\n",
      "Cost at Observation 20300: 0.0176338467273578\n",
      "Cost at Observation 20400: 0.012089927682535173\n",
      "Cost at Observation 20500: 0.009013736564611463\n",
      "Cost at Observation 20600: 0.007132083456394324\n",
      "Cost at Observation 20700: 0.005879881192951723\n",
      "Cost at Observation 20800: 0.004992311134096548\n",
      "Cost at Observation 20900: 0.004332671576550807\n",
      "Cost at Observation 21000: 0.0038242302709054197\n",
      "Cost at Observation 21100: 0.003420899879325826\n",
      "Cost at Observation 21200: 0.0030934456901671173\n",
      "Cost at Observation 21300: 0.002822478001801336\n",
      "Cost at Observation 21400: 0.0025946533196165426\n",
      "Cost at Observation 21500: 0.0024005000478082203\n",
      "Cost at Observation 21600: 0.0022331155232596877\n",
      "Cost at Observation 21700: 0.0020873540184824222\n",
      "Cost at Observation 21800: 0.0019593033468907443\n",
      "Cost at Observation 21900: 0.0018459374508891797\n",
      "Cost at Observation 22000: 0.0017448797931904692\n",
      "Cost at Observation 22100: 0.0016542385080710496\n",
      "Cost at Observation 22200: 0.0015724892034787916\n",
      "Cost at Observation 22300: 0.0014983901187504262\n",
      "Cost at Observation 22400: 0.001430919696702568\n",
      "Cost at Observation 22500: 0.0013692299665092893\n",
      "Cost at Observation 22600: 0.0013126112635870526\n",
      "Cost at Observation 22700: 0.0012604652008738988\n",
      "Cost at Observation 22800: 0.001212283728277955\n",
      "Cost at Observation 22900: 0.0011676327408554031\n",
      "Cost at Observation 23000: 0.0011261391250098492\n",
      "Cost at Observation 23100: 0.0010874804310989068\n",
      "Cost at Observation 23200: 0.0010513765723773139\n",
      "Cost at Observation 23300: 0.0010175831017476527\n",
      "Cost at Observation 23400: 0.000985885727636328\n",
      "Cost at Observation 23500: 0.0009560958108415336\n",
      "Cost at Observation 23600: 0.0009280466438061209\n",
      "Cost at Observation 23700: 0.0009015903583686279\n",
      "Cost at Observation 23800: 0.0008765953416723051\n",
      "Cost at Observation 23900: 0.0008529440655135367\n",
      "Cost at Observation 24000: 0.0008305312540441072\n",
      "Cost at Observation 24100: 0.0008092623299200823\n",
      "Cost at Observation 24200: 0.0007890520907974874\n",
      "Cost at Observation 24300: 0.000769823577339201\n",
      "Cost at Observation 24400: 0.0007515071011929422\n",
      "Cost at Observation 24500: 0.000734039407200684\n",
      "Cost at Observation 24600: 0.0007173629487144155\n",
      "Cost at Observation 24700: 0.0007014252586170899\n",
      "Cost at Observation 24800: 0.000686178401629396\n",
      "Cost at Observation 24900: 0.0006715784959169925\n",
      "Cost at Observation 25000: 0.0006575852939874143\n",
      "Cost at Observation 25100: 0.0006441618144854339\n",
      "Cost at Observation 25200: 0.0006312740178207668\n",
      "Cost at Observation 25300: 0.0006188905196691648\n",
      "Cost at Observation 25400: 0.0006069823372843996\n",
      "Cost at Observation 25500: 0.0005955226643274721\n",
      "Cost at Observation 25600: 0.0005844866705407067\n",
      "Cost at Observation 25700: 0.0005738513231311223\n",
      "Cost at Observation 25800: 0.0005635952271690174\n",
      "Cost at Observation 25900: 0.0005536984826803139\n",
      "Cost at Observation 26000: 0.000544142556434798\n",
      "Cost at Observation 26100: 0.0005349101666968819\n",
      "Cost at Observation 26200: 0.0005259851794344758\n",
      "Cost at Observation 26300: 0.000517352514683895\n",
      "Cost at Observation 26400: 0.000508998061924229\n",
      "Cost at Observation 26500: 0.0005009086034745024\n",
      "Cost at Observation 26600: 0.0004930717450322687\n",
      "Cost at Observation 26700: 0.0004854758525953279\n",
      "Cost at Observation 26800: 0.0004781099950902892\n",
      "Cost at Observation 26900: 0.0004709638921161549\n",
      "Cost at Observation 27000: 0.0004640278662768645\n",
      "Cost at Observation 27100: 0.0004572927996422681\n",
      "Cost at Observation 27200: 0.00045075009392496116\n",
      "Cost at Observation 27300: 0.000444391634009252\n",
      "Cost at Observation 27400: 0.0004382097545065834\n",
      "Cost at Observation 27500: 0.0004321972090495574\n",
      "Cost at Observation 27600: 0.0004263471420670794\n",
      "Cost at Observation 27700: 0.0004206530628088421\n",
      "Cost at Observation 27800: 0.00041510882141261867\n",
      "Cost at Observation 27900: 0.0004097085868311917\n",
      "Cost at Observation 28000: 0.00040444682644999203\n",
      "Cost at Observation 28100: 0.00039931828725031177\n",
      "Cost at Observation 28200: 0.0003943179783778688\n",
      "Cost at Observation 28300: 0.0003894411550008388\n",
      "Cost at Observation 28400: 0.00038468330334404685\n",
      "Cost at Observation 28500: 0.0003800401268023472\n",
      "Cost at Observation 28600: 0.00037550753304401276\n",
      "Cost at Observation 28700: 0.00037108162202029366\n",
      "Cost at Observation 28800: 0.0003667586748102025\n",
      "Cost at Observation 28900: 0.0003625351432331433\n",
      "Cost at Observation 29000: 0.00035840764016623186\n",
      "Cost at Observation 29100: 0.0003543729305148234\n",
      "Cost at Observation 29200: 0.00035042792278199334\n",
      "Cost at Observation 29300: 0.0003465696611928289\n",
      "Cost at Observation 29400: 0.00034279531833294883\n",
      "Cost at Observation 29500: 0.00033910218825711853\n",
      "Cost at Observation 29600: 0.0003354876800407144\n",
      "Cost at Observation 29700: 0.00033194931173590917\n",
      "Cost at Observation 29800: 0.0003284847047037834\n",
      "Cost at Observation 29900: 0.00032509157829812484\n",
      "Cost at Observation 30000: 0.0003217677448734583\n",
      "Cost at Observation 30100: 0.0003185111050940722\n",
      "Cost at Observation 30200: 0.0003153196435255855\n",
      "Cost at Observation 30300: 0.00031219142448682326\n",
      "Cost at Observation 30400: 0.00030912458814521545\n",
      "Cost at Observation 30500: 0.00030611734684059786\n",
      "Cost at Observation 30600: 0.00030316798161829996\n",
      "Cost at Observation 30700: 0.0003002748389626211\n",
      "Cost at Observation 30800: 0.0002974363277129146\n",
      "Cost at Observation 30900: 0.0002946509161544938\n",
      "Cost at Observation 31000: 0.0002919171292670268\n",
      "Cost at Observation 31100: 0.0002892335461298534\n",
      "Cost at Observation 31200: 0.00028659879746278287\n",
      "Cost at Observation 31300: 0.0002840115633039203\n",
      "Cost at Observation 31400: 0.00028147057080940883\n",
      "Cost at Observation 31500: 0.00027897459217064106\n",
      "Cost at Observation 31600: 0.00027652244264082495\n",
      "Cost at Observation 31700: 0.0002741129786653467\n",
      "Cost at Observation 31800: 0.0002717450961060413\n",
      "Cost at Observation 31900: 0.0002694177285591438\n",
      "Cost at Observation 32000: 0.00026712984575792204\n",
      "Cost at Observation 32100: 0.0002648804520549881\n",
      "Cost at Observation 32200: 0.0002626685849811769\n",
      "Cost at Observation 32300: 0.0002604933138749902\n",
      "Cost at Observation 32400: 0.0002583537385811594\n",
      "Cost at Observation 32500: 0.0002562489882099958\n",
      "Cost at Observation 32600: 0.00025417821995907974\n",
      "Cost at Observation 32700: 0.00025214061799006703\n",
      "Cost at Observation 32800: 0.00025013539235927936\n",
      "Cost at Observation 32900: 0.00024816177799918726\n",
      "Cost at Observation 33000: 0.00024621903374678683\n",
      "Cost at Observation 33100: 0.00024430644141820154\n",
      "Cost at Observation 33200: 0.00024242330492495447\n",
      "Cost at Observation 33300: 0.00024056894943046524\n",
      "Cost at Observation 33400: 0.00023874272054643755\n",
      "Cost at Observation 33500: 0.00023694398356480416\n",
      "Cost at Observation 33600: 0.00023517212272156386\n",
      "Cost at Observation 33700: 0.00023342654049828367\n",
      "Cost at Observation 33800: 0.00023170665694938235\n",
      "Cost at Observation 33900: 0.000230011909062413\n",
      "Cost at Observation 34000: 0.00022834175014368072\n",
      "Cost at Observation 34100: 0.00022669564923285913\n",
      "Cost at Observation 34200: 0.0002250730905393872\n",
      "Cost at Observation 34300: 0.00022347357290653002\n",
      "Cost at Observation 34400: 0.00022189660929521947\n",
      "Cost at Observation 34500: 0.00022034172629100464\n",
      "Cost at Observation 34600: 0.00021880846363078025\n",
      "Cost at Observation 34700: 0.00021729637374984746\n",
      "Cost at Observation 34800: 0.00021580502134653065\n",
      "Cost at Observation 34900: 0.00021433398296579238\n",
      "Cost at Observation 35000: 0.00021288284659895987\n",
      "Cost at Observation 35100: 0.00021145121129945054\n",
      "Cost at Observation 35200: 0.00021003868681405223\n",
      "Cost at Observation 35300: 0.00020864489322931366\n",
      "Cost at Observation 35400: 0.00020726946063137882\n",
      "Cost at Observation 35500: 0.00020591202877915364\n",
      "Cost at Observation 35600: 0.00020457224678969456\n",
      "Cost at Observation 35700: 0.00020324977283781723\n",
      "Cost at Observation 35800: 0.00020194427386459454\n",
      "Cost at Observation 35900: 0.00020065542529829777\n",
      "Cost at Observation 36000: 0.0001993829107864472\n",
      "Cost at Observation 36100: 0.00019812642193730714\n",
      "Cost at Observation 36200: 0.000196885658070491\n",
      "Cost at Observation 36300: 0.0001956603259778985\n",
      "Cost at Observation 36400: 0.0001944501396932075\n",
      "Cost at Observation 36500: 0.00019325482026969843\n",
      "Cost at Observation 36600: 0.00019207409556596677\n",
      "Cost at Observation 36700: 0.0001909077000399676\n",
      "Cost at Observation 36800: 0.00018975537455050381\n",
      "Cost at Observation 36900: 0.00018861686616493607\n",
      "Cost at Observation 37000: 0.0001874919279748912\n",
      "Cost at Observation 37100: 0.00018638031891785918\n",
      "Cost at Observation 37200: 0.0001852818036047891\n",
      "Cost at Observation 37300: 0.00018419615215579444\n",
      "Cost at Observation 37400: 0.00018312314003763753\n",
      "Cost at Observation 37500: 0.0001820625479115437\n",
      "Cost at Observation 37600: 0.00018101416148179502\n",
      "Cost at Observation 37700: 0.00017997777135343214\n",
      "Cost at Observation 37800: 0.00017895317289195694\n",
      "Cost at Observation 37900: 0.0001779401660890337\n",
      "Cost at Observation 38000: 0.00017693855543285595\n",
      "Cost at Observation 38100: 0.00017594814978217995\n",
      "Cost at Observation 38200: 0.0001749687622450235\n",
      "Cost at Observation 38300: 0.00017400021006114217\n",
      "Cost at Observation 38400: 0.00017304231448894876\n",
      "Cost at Observation 38500: 0.00017209490069543268\n",
      "Cost at Observation 38600: 0.0001711577976491899\n",
      "Cost at Observation 38700: 0.0001702308380194508\n",
      "Cost at Observation 38800: 0.000169313858074554\n",
      "Cost at Observation 38900: 0.00016840669758741748\n",
      "Cost at Observation 39000: 0.00016750919974067754\n",
      "Cost at Observation 39100: 0.00016662121103804776\n",
      "Cost at Observation 39200: 0.00016574258121634483\n",
      "Cost at Observation 39300: 0.000164873163159959\n",
      "Cost at Observation 39400: 0.0001640128128198779\n",
      "Cost at Observation 39500: 0.0001631613891341552\n",
      "Cost at Observation 39600: 0.00016231875395082305\n",
      "Cost at Observation 39700: 0.0001614847719528043\n",
      "Cost at Observation 39800: 0.00016065931058604563\n",
      "Cost at Observation 39900: 0.00015984223998898446\n",
      "Cost at Observation 40000: 0.00015903343292534742\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    clf.fit(X, 0.0)\n",
    "    clf.fit(x2,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [(136, 0.25), (137,1.0), (139, 0.333333), (141, 0.115385), (143, 0.029412), (156, 1.0), (157, 0.37931), (158, 0.25), (160, 1.0), (164, 0.37931), (176, 1.0), (177, 0.0625), (183, 1.0), (186, 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [3] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =math.fsum([v[1] * w[v[0]] for v in x]) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 1 / (1 + math.exp(-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = A - Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = [(x[0],x[1]*da) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.86832980505137"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(math.fsum([x**2 for x in w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
