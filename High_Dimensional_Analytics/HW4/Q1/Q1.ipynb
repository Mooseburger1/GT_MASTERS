{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Given the following optimization problems in matrix form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Ordinary Least Squares:}\\ \\ \\ \\  min_{\\beta} || y - X \\beta||_2^2\n",
    "\\\\\n",
    "\\text{Ridge:}\\ \\ \\ \\ min_{\\beta} || y-X \\beta||_2^2 + \\lambda || \\beta ||_2^2\n",
    "\\\\\n",
    "\\text{Lasso:}\\ \\ \\ \\ min_{\\beta} ||y - X \\beta ||^2_2 + \\lambda ||\\beta||_1\n",
    "\\\\\n",
    "\\text{Elastic Net:}\\ \\ \\ \\ min_{\\beta} || y - X \\beta ||_2^2 + \\lambda_L || \\beta ||_1 + \\lambda_R ||\\beta||_2^2\n",
    "\\\\\n",
    "\\end{equation}\n",
    "\n",
    "Where\n",
    "* $y \\in R^n$ is the vector of observed outputs, n is the number of observations\n",
    "* $X \\in R^{n\\ x\\ p}$ is the matrix of features, p is the number of features\n",
    "* $\\beta \\in R^p$ is the vector of parameters to be estimated\n",
    "* $\\lambda \\geq 0$, where $\\lambda$ is a hyperparameter controlling the shrinkage penalty\n",
    "\n",
    "Assuming X is *orthonormal*\n",
    "\n",
    "### (a) Show that $\\hat{\\beta}^{ols} = X^Ty$ is a closed form solution for the Ordinary Least Squares regression problem.\n",
    "\n",
    "## **Answer**\n",
    "\n",
    "For X to be orthonormal, that means:\n",
    "* All its vectors are unit length\n",
    "* All its vectors are orthogonal\n",
    "* All its vectors are linearly independent\n",
    "* Its determinant is 1\n",
    "* And most importantly $XX^T = X^TX = I$\n",
    "\n",
    "\\begin{equation}\n",
    "min_{\\beta} || y - X \\beta||_2^2 \\ \\ \\ \\ (1)\n",
    "\\end{equation}\n",
    "\n",
    "Taking the derivative of (1) with respect to $\\beta$ and setting equal to 0\n",
    "\n",
    "\\begin{equation}\n",
    "= 2(y-X\\beta)X\n",
    "\\\\\n",
    "= (2y - 2X\\beta)X\n",
    "\\\\\n",
    "= (2X^Ty - 2X^TX\\beta) = 0\n",
    "\\\\\n",
    "= 2X^Ty = 2X^TX\\beta\n",
    "\\\\\n",
    "X^Ty = X^TX\\beta \\ \\ \\ \\ (2)\n",
    "\\end{equation}\n",
    "\n",
    "Solving (2) for $\\beta$\n",
    "\n",
    "\\begin{equation}\n",
    "(X^TX)^{-1}X^Ty = \\beta \\ \\ \\ \\ (3)\n",
    "\\end{equation}\n",
    "\n",
    "Taking note of the last bullet point above $X^TX = I$ (3) becomes\n",
    "\n",
    "\\begin{equation}\n",
    "(I)^{-1}X^Ty = \\beta\n",
    "\\\\\n",
    "= (I)X^Ty = \\beta\n",
    "\\end{equation}\n",
    "\n",
    "Therefore\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\\hat{\\beta}^{ols} = X^Ty}\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Show that $\\hat{\\beta}^{ridge} = (1 + \\lambda)^{-1} \\hat{\\beta}^{ols}$ is a closed form solution for the Ridge regression problem.\n",
    "\n",
    "## **Answer**\n",
    "\n",
    "**Note**: Since a lot of these steps are repetitive from above, I won't be as explicit in my derivation\n",
    "\n",
    "\\begin{equation}\n",
    "|| y-X \\beta||_2^2 + \\lambda || \\beta ||_2^2\\ \\ \\ \\ (1)\n",
    "\\end{equation}\n",
    "\n",
    "Taking the derivative of (1) with respect $\\beta$ and setting equal to yields\n",
    "\n",
    "\\begin{equation}\n",
    "= (2y-2X\\beta)X + (2\\lambda\\beta) = 0\n",
    "\\\\\n",
    "= (2X^Ty - 2X^TX\\beta) + (2\\lambda\\beta) = 0\n",
    "\\\\\n",
    "= (X^Ty - X^TX\\beta) + (\\lambda\\beta) = 0\\ \\ \\ \\ (2)\n",
    "\\end{equation}\n",
    "\n",
    "Solving (2) for $\\beta$ yields\n",
    "\n",
    "\\begin{equation}\n",
    "X^Ty = X^TX\\beta + \\lambda\\beta\n",
    "\\\\\n",
    "X^Ty = (X^TX + \\lambda I)\\beta\n",
    "\\\\\n",
    "(X^TX + \\lambda I)^{-1}X^Ty = \\beta\n",
    "\\\\\n",
    "(I + \\lambda I)^{-1}X^Ty = \\beta\\ \\ \\ \\ (3)\n",
    "\\end{equation}\n",
    "\n",
    "Remembering from part (a) that $X^Ty$ is the solution to $\\hat{\\beta}^{ols}$ (3) becomes\n",
    "\n",
    "\\begin{equation}\n",
    "(I + \\lambda I)^{-1}\\hat{\\beta}^{ols} = \\beta\n",
    "\\end{equation}\n",
    "\n",
    "Therefore\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\\hat{\\beta}^{ridge} = (1 + \\lambda)^{-1}\\hat{\\beta}^{ols}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Show that ...\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{lasso}_j = \n",
    "\\begin{cases}\n",
    "\\hat{\\beta}^{ols}_j - \\frac{\\lambda}{2}\\ \\ \\ \\ \\ \\text{if}\\ \\hat{\\beta}^{ols}_j > \\frac{\\lambda}{2}\n",
    "\\\\\n",
    "0\\ \\ \\ \\ \\ \\text{if}\\ -\\frac{\\lambda}{2} \\leq \\hat{\\beta}^{ols}_j \\leq \\frac{\\lambda}{2}\n",
    "\\\\\n",
    "\\hat{\\beta}^{ols}_j + \\frac{\\lambda}{2}\\ \\ \\ \\ \\ \\text{if}\\ \\hat{\\beta}^{ols}_j < - \\frac{\\lambda}{2}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "... is a closed form solution for the Lasso regression problem.\n",
    "\n",
    "## **Answer**\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "|| y-X \\beta||_2^2 + \\lambda || \\beta ||_1\\ \\ \\ \\ (1)\n",
    "\\end{equation}\n",
    "\n",
    "Taking the derivative of (1) on the left side of the + with respect to $\\beta$ yields\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "= (2X^Ty - 2X^TX\\beta) + \\frac{\\partial \\lambda ||\\beta||_1}{\\partial \\beta} \\ \\ \\ \\ \\ (2)\n",
    "\\end{equation}\n",
    "\n",
    "Reducing (2) with respect to the orthonormal case $XX^T = X^TX = I$ and accouting for the first part being equivalent to $\\hat{\\beta}^{ols}$\n",
    "\n",
    "\\begin{equation}\n",
    "= (2\\hat{\\beta}^{ols} - 2I\\beta) + \\frac{\\partial \\lambda ||\\beta||_1}{\\partial \\beta}\\\\\n",
    "= (2\\hat{\\beta}^{ols} - 2\\beta) + \\frac{\\partial \\lambda ||\\beta||_1}{\\partial \\beta}\\ \\ \\ \\ \\ (3)\n",
    "\\end{equation}\n",
    "\n",
    "Accouting for the fact that the right side of the + is a subgradient where:\n",
    "\n",
    "\\begin{equation}\n",
    "\\partial Lasso = 2\\hat{\\beta}^{ols} - 2\\beta_j +\n",
    "\\begin{cases}\n",
    "-\\lambda\\ \\ \\ \\ \\  \\text{when}\\ \\beta_j > 0\n",
    "\\\\\n",
    "[-\\lambda, \\lambda]\\ \\ \\ \\ \\ \\text{when}\\ \\beta_j = 0\n",
    "\\\\\n",
    "\\lambda\\ \\ \\ \\ \\ \\text{when}\\ \\beta_j < 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "and dividing the entire equation by 2 then setting all cases equal to 0 leaves the cases of \n",
    "\n",
    "\\begin{equation}\n",
    "= \\begin{cases}\n",
    "\\hat{\\beta}^{ols} - \\beta_j - \\frac{\\lambda}{2}\\ \\ \\ \\ \\text{when}\\ \\beta_j > 0 \\\\\n",
    "[-\\hat{\\beta}^{ols} - \\frac{\\lambda}{2} , -\\hat{\\beta}^{ols} + \\frac{\\lambda}{2}]\\ \\ \\ \\ \\text{when}\\ \\beta_j = 0 \\\\ \n",
    "\\hat{\\beta}^{ols} - \\beta_j + \\frac{\\lambda}{2}\\ \\ \\ \\ \\text{when}\\ \\beta_j < 0\\ \\ \\ \\ \\ (4)\n",
    "\\end{cases}\n",
    "=0\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Setting Case 1 = 0 and solving for $\\beta_j$:\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{ols} - \\beta_j - \\frac{\\lambda}{2} = 0\\\\\n",
    "\\beta_j = \\hat{\\beta}^{ols} - \\frac{\\lambda}{2}\\ \\ \\ \\ \\ (5)\n",
    "\\end{equation}\n",
    "\n",
    "Case 1 has the constraint that $\\beta_j$ > 0, so (5) is only true if $\\hat{\\beta}^{ols}$ > $\\frac{\\lambda}{2}$\n",
    "\n",
    "For Case 2; $\\beta_j$ = 0 and we need the interval $[-\\hat{\\beta}^{ols} - \\frac{\\lambda}{2} , -\\hat{\\beta}^{ols} + \\frac{\\lambda}{2}]$ to contain 0 so that $\\beta_j=0$ is an optimum\n",
    "\n",
    "\\begin{equation}\n",
    "-\\hat{\\beta}^{ols} - \\frac{\\lambda}{2} = 0\\ \\ ,\\ \\ \\hat{\\beta}^{ols} = - \\frac{\\lambda}{2}\\ \\ \\ \\  (6)\n",
    "\\\\\n",
    "-\\hat{\\beta}^{ols} + \\frac{\\lambda}{2} = 0\\ \\ \\ , \\ \\ \\ \\hat{\\beta}^{ols} = \\frac{\\lambda}{2}\\ \\ \\ \\ (7)\n",
    "\\end{equation}\n",
    "\n",
    "Setting Case 3 = 0 and solving for $\\beta_j$:\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{ols} - \\beta_j +  \\frac{\\lambda}{2} = 0\\\\\n",
    "\\beta_j = \\hat{\\beta}^{ols} + \\frac{\\lambda}{2}\\ \\ \\ \\ \\ (8)\n",
    "\\end{equation}\n",
    "\n",
    "Case 3 has the constraint that $\\beta_j$ < 0, so (8) is only true if $\\hat{\\beta}^{ols}$  < -$\\frac{\\lambda}{2}$\n",
    "\n",
    "Combining equations (5), (6), (7), (8) with their respective response to the constraints yields:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\hat{\\beta}^{lasso}_j = \n",
    "\\begin{cases}\n",
    "\\hat{\\beta}^{ols}_j - \\frac{\\lambda}{2}\\ \\ \\ \\ \\text{if}\\ \\hat{\\beta}^{ols}_j > \\frac{\\lambda}{2}\\\\\n",
    "0\\ \\ \\ \\ \\ \\ \\text{if}\\ -\\frac{\\lambda}{2} \\leq \\hat{\\beta}^{ols}_j \\leq \\frac{\\lambda}{2}\\\\\n",
    "\\hat{\\beta}^{ols}_j + \\frac{\\lambda}{2}\\ \\ \\ \\  \\text{if}\\ \\hat{\\beta}^{ols}_j < -\\frac{\\lambda}{2}\n",
    "\\end{cases}\n",
    "}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)Using the derivations in parts a, b, and c, derive a closed form solution for the Elastic Net regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Elastic Net is the combination of L1 and L2 regularization, we can start from Equation (4) from above in part (c) and simply add the derivative of the L2 loss term\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\lambda_R ||\\beta||^2_2}{\\partial \\beta} = 2 \\lambda_r \\beta\\ \\ \\ \\ \\ (1)\n",
    "\\end{equation}\n",
    "\n",
    "adding (1) into (4) from above in part (c) and accounting for the division by 2 from part (c) before equation (4) yields\n",
    "\n",
    "\\begin{equation}\n",
    "= \\begin{cases}\n",
    "\\hat{\\beta}^{ols} - \\beta_j - \\frac{\\lambda_L}{2} +  \\lambda_R \\beta_j \\ \\ \\ \\ \\text{when}\\ \\beta_j > 0 \\\\\n",
    "[-\\hat{\\beta}^{ols} - \\frac{\\lambda_L}{2} , -\\hat{\\beta}^{ols} + \\frac{\\lambda_L}{2}]\\ \\ \\ \\ \\text{when}\\ \\beta_j = 0 \\\\ \n",
    "\\hat{\\beta}^{ols} - \\beta_j + \\frac{\\lambda_L}{2} + \\lambda_R \\beta_j\\ \\ \\ \\ \\text{when}\\ \\beta_j < 0\\ \\ \\ \\ \\\n",
    "\\end{cases}\n",
    "=0\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Setting Case 1 to 0 and solving for $\\beta_j$\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{ols} - \\beta_j + \\lambda_R \\beta_j - \\frac{\\lambda_L}{2} = 0\n",
    "\\\\\n",
    "\\beta_j (1 + \\lambda_R) = \\hat{\\beta}^{ols} - \\frac{\\lambda_L}{2}\n",
    "\\\\\n",
    "\\beta_J = \\frac{\\hat{\\beta}^{ols} - \\frac{\\lambda_L}{2}}{(1 + \\lambda_R)}\n",
    "\\end{equation}\n",
    "\n",
    "Case 2 holds true from part (c)\n",
    "\n",
    "Setting Case 3 equal to 0 and solving for $\\beta_j$\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{ols} - \\beta_j + \\lambda_R \\beta_j + \\frac{\\lambda_L}{2} = 0\n",
    "\\\\\n",
    "\\beta_j (1 + \\lambda_R) = \\hat{\\beta}^{ols} - \\frac{\\lambda_L}{2}\n",
    "\\\\\n",
    "\\beta_J = \\frac{\\hat{\\beta}^{ols} + \\frac{\\lambda_L}{2}}{(1 + \\lambda_R)}\n",
    "\\end{equation}\n",
    "\n",
    "Compiling all results yields\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\hat{\\beta}^{EN}_j = \n",
    "\\begin{cases}\n",
    "\\frac{\\hat{\\beta}^{ols}_j - \\frac{\\lambda}{2}}{1 + \\lambda_R}\\ \\ \\ \\ \\text{if}\\ \\hat{\\beta}^{ols}_j > \\frac{\\lambda}{2}\\\\\n",
    "0\\ \\ \\ \\ \\ \\ \\text{if}\\ -\\frac{\\lambda}{2} \\leq \\hat{\\beta}^{ols}_j \\leq \\frac{\\lambda}{2}\\\\\n",
    "\\frac{\\hat{\\beta}^{ols}_j + \\frac{\\lambda}{2}}{1+\\lambda_R}\\ \\ \\ \\  \\text{if}\\ \\hat{\\beta}^{ols}_j < -\\frac{\\lambda}{2}\n",
    "\\end{cases}\n",
    "}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
